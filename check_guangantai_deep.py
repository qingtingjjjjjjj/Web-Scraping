import requests
import subprocess
import concurrent.futures
import time
import csv
import os

# ===== é…ç½® =====
LIVE_FILE = "live.txt"
WHITELIST_FILE = "æ¸¯æ¾³å°_whitelist.txt"
RESULTS_FILE = "æ¸¯æ¾³å°_test_results.csv"
RETRIES = 2
TIMEOUT = 3
CONCURRENT_WORKERS = 50
FFPROBE_INITIAL = "3000000"  # åˆæµ‹ 3 ç§’
FFPROBE_RETRY = "5000000"    # é‡æµ‹ 5 ç§’
MAX_LATENCY = 20             # æœ€å¤§å…è®¸å»¶è¿Ÿï¼ˆç§’ï¼‰

# ===== HTTP + å»¶è¿Ÿæµ‹è¯• =====
def test_http_latency(url):
    for _ in range(RETRIES):
        try:
            start = time.time()
            r = requests.head(url, timeout=TIMEOUT)
            latency = time.time() - start
            if r.status_code == 200:
                return r.status_code, latency
        except:
            try:
                start = time.time()
                r = requests.get(url, stream=True, timeout=TIMEOUT)
                r.iter_content(1024)
                latency = time.time() - start
                if r.status_code == 200:
                    return r.status_code, latency
            except:
                time.sleep(0.2)
    return None, None

# ===== ffprobe æ’­æ”¾æ£€æµ‹ï¼ˆåˆæµ‹/é‡æµ‹ï¼‰ =====
def test_playable(url, analyzeduration):
    try:
        result = subprocess.run(
            [
                "ffprobe",
                "-v", "error",
                "-analyzeduration", analyzeduration,
                "-timeout", str(TIMEOUT*1000000),
                "-i", url
            ],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        return result.returncode == 0
    except:
        return False

# ===== æµ‹è¯•å•æ¡æº =====
def test_source(line):
    line = line.strip()
    if not line or "," not in line:
        return None
    name, url = line.split(",", 1)
    
    status, latency = test_http_latency(url)
    playable = False
    fail_reason = ""
    if status == 200 and latency <= MAX_LATENCY:
        # åˆæµ‹ 3 ç§’
        playable = test_playable(url, FFPROBE_INITIAL)
        if not playable:
            # åˆæµ‹å¤±è´¥ï¼Œé‡æµ‹ 5 ç§’
            playable = test_playable(url, FFPROBE_RETRY)
            if not playable:
                fail_reason = "ffprobe failed"
    else:
        fail_reason = "HTTP failed or latency too high"

    return {
        "name": name,
        "url": url,
        "http_status": status if status else "Fail",
        "latency": round(latency, 2) if latency else None,
        "playable": playable,
        "fail_reason": fail_reason
    }

# ===== ä» live.txt ä¸­æå–æ¸¯æ¾³å°åˆ†ç»„ =====
def extract_guangantai(lines):
    group = []
    in_group = False
    for line in lines:
        line = line.strip()
        if line.startswith("æ¸¯æ¾³å°,#genre#"):
            in_group = True
            continue
        if in_group:
            if line.endswith("#genre#") or line == "" or line.startswith("ğŸ‡¨ğŸ‡³"):
                break
            group.append(line)
    return group

# ===== è¯»å– live.txt =====
with open(LIVE_FILE, "r", encoding="utf-8") as f:
    lines = f.readlines()

guangantai_lines = extract_guangantai(lines)

# ===== å¹¶å‘æµ‹é€Ÿ =====
results = []
with concurrent.futures.ThreadPoolExecutor(max_workers=CONCURRENT_WORKERS) as executor:
    for res in executor.map(test_source, guangantai_lines):
        if res:
            results.append(res)

# ===== å†™å…¥ whitelist.txt =====
with open(WHITELIST_FILE, "w", encoding="utf-8") as f:
    for r in results:
        if r["http_status"] == 200 and r["playable"]:
            f.write(f"{r['name']},{r['url']}\n")

# ===== å†™å…¥ test_results.csv =====
with open(RESULTS_FILE, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["name","url","http_status","latency","playable","fail_reason"])
    writer.writeheader()
    writer.writerows(results)

print(f"âœ… æ¸¯æ¾³å°æµ‹é€Ÿå®Œæˆï¼Œå¯ç”¨æºå†™å…¥ {WHITELIST_FILE}ï¼Œè¯¦ç»†ç»“æœå†™å…¥ {RESULTS_FILE}")
