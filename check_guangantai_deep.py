import requests
import subprocess
import concurrent.futures
import time
import csv
import os

# ===== é…ç½® =====
LIVE_FILE = "live.txt"               # æ ¹ç›®å½•æ€»ç›´æ’­æºæ–‡ä»¶
WHITELIST_FILE = "æ¸¯æ¾³å°_whitelist.txt"
RESULTS_FILE = "æ¸¯æ¾³å°_test_results.csv"
RETRIES = 2
TIMEOUT = 3
CONCURRENT_WORKERS = 50
FFPROBE_ANALYZE = "3000000"  # å¾®ç§’çº§åˆ†æï¼Œ3 ç§’
MAX_LATENCY = 20             # æœ€å¤§å…è®¸å»¶è¿Ÿï¼ˆç§’ï¼‰

# ===== HTTP + å»¶è¿Ÿæµ‹è¯• =====
def test_http_latency(url):
    for _ in range(RETRIES):
        try:
            start = time.time()
            # å°è¯• HEAD è¯·æ±‚
            r = requests.head(url, timeout=TIMEOUT)
            latency = time.time() - start
            if r.status_code == 200:
                return r.status_code, latency
        except:
            # HEAD è¯·æ±‚å¤±è´¥ï¼Œå°è¯• GET å‰ 1 KB
            try:
                start = time.time()
                r = requests.get(url, stream=True, timeout=TIMEOUT)
                r.iter_content(1024)
                latency = time.time() - start
                if r.status_code == 200:
                    return r.status_code, latency
            except:
                time.sleep(0.2)
    return None, None

# ===== ffprobe æ’­æ”¾æ£€æµ‹ï¼ˆå¤±è´¥é‡è¯•ä¸€æ¬¡ï¼‰ =====
def test_playable(url):
    for attempt in range(2):
        try:
            result = subprocess.run(
                [
                    "ffprobe",
                    "-v", "error",
                    "-analyzeduration", FFPROBE_ANALYZE,
                    "-timeout", str(TIMEOUT*1000000),
                    "-i", url
                ],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            if result.returncode == 0:
                return True
        except:
            time.sleep(0.2)
    return False

# ===== æµ‹è¯•å•æ¡æº =====
def test_source(line):
    line = line.strip()
    if not line or "," not in line:
        return None
    name, url = line.split(",", 1)
    
    status, latency = test_http_latency(url)
    playable = False
    if status == 200 and latency <= MAX_LATENCY:
        playable = test_playable(url)
    
    return {
        "name": name,
        "url": url,
        "http_status": status if status else "Fail",
        "latency": round(latency, 2) if latency else None,
        "playable": playable
    }

# ===== ä» live.txt ä¸­æå–æ¸¯æ¾³å°åˆ†ç»„ =====
def extract_guangantai(lines):
    group = []
    in_group = False
    for line in lines:
        line = line.strip()
        if line.startswith("æ¸¯æ¾³å°,#genre#"):
            in_group = True
            continue
        if in_group:
            if line.endswith("#genre#") or line == "" or line.startswith("ğŸ‡¨ğŸ‡³"):
                break
            group.append(line)
    return group

# ===== è¯»å– live.txt =====
with open(LIVE_FILE, "r", encoding="utf-8") as f:
    lines = f.readlines()

guangantai_lines = extract_guangantai(lines)

# ===== å¹¶å‘æµ‹é€Ÿ =====
results = []
with concurrent.futures.ThreadPoolExecutor(max_workers=CONCURRENT_WORKERS) as executor:
    for res in executor.map(test_source, guangantai_lines):
        if res:
            results.append(res)

# ===== å†™å…¥ whitelist.txt =====
with open(WHITELIST_FILE, "w", encoding="utf-8") as f:
    for r in results:
        if r["http_status"] == 200 and r["playable"]:
            f.write(f"{r['name']},{r['url']}\n")

# ===== å†™å…¥ test_results.csv =====
with open(RESULTS_FILE, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["name","url","http_status","latency","playable"])
    writer.writeheader()
    writer.writerows(results)

print(f"âœ… æ¸¯æ¾³å°æµ‹é€Ÿå®Œæˆï¼Œå¯ç”¨æºå†™å…¥ {WHITELIST_FILE}ï¼Œè¯¦ç»†ç»“æœå†™å…¥ {RESULTS_FILE}")
