import requests
import subprocess
import concurrent.futures
import time
import csv
import os

# ===== é…ç½® =====
LIVE_FILE = "live.txt"               # æ ¹ç›®å½•çš„æ€»ç›´æ’­æºæ–‡ä»¶
WHITELIST_FILE = "æ¸¯æ¾³å°_whitelist.txt"
RESULTS_FILE = "æ¸¯æ¾³å°_test_results.csv"
RETRIES = 2
TIMEOUT = 3
CONCURRENT_WORKERS = 50
FFPROBE_ANALYZE = "500000"  # å¾®ç§’çº§åˆ†æï¼Œè¶Šå°è¶Šå¿«

# ===== HTTP + å»¶è¿Ÿæµ‹è¯• =====
def test_http_latency(url):
    for _ in range(RETRIES):
        try:
            start = time.time()
            r = requests.head(url, timeout=TIMEOUT)
            latency = time.time() - start
            if r.status_code == 200:
                return r.status_code, latency
        except:
            time.sleep(0.2)
    return None, None

# ===== ffprobe æµ‹è¯•æ’­æ”¾ =====
def test_playable(url):
    try:
        result = subprocess.run(
            [
                "ffprobe",
                "-v", "error",
                "-analyzeduration", FFPROBE_ANALYZE,
                "-timeout", str(TIMEOUT*1000000),
                "-i", url
            ],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        return result.returncode == 0
    except:
        return False

# ===== æµ‹è¯•å•æ¡æº =====
def test_source(line):
    line = line.strip()
    if not line or "," not in line:
        return None
    name, url = line.split(",", 1)
    
    status, latency = test_http_latency(url)
    playable = False
    if status == 200:
        playable = test_playable(url)
    
    return {
        "name": name,
        "url": url,
        "http_status": status if status else "Fail",
        "latency": round(latency, 2) if latency else None,
        "playable": playable
    }

# ===== ä» live.txt ä¸­æå–æ¸¯æ¾³å°åˆ†ç»„ =====
def extract_guangantai(lines):
    group = []
    in_group = False
    for line in lines:
        line = line.strip()
        if line.startswith("æ¸¯æ¾³å°,#genre#"):
            in_group = True
            continue
        if in_group:
            if line.startswith("ğŸ‡¨ğŸ‡³") or line.endswith("#genre#") or line == "":
                break
            group.append(line)
    return group

# ===== è¯»å– live.txt =====
with open(LIVE_FILE, "r", encoding="utf-8") as f:
    lines = f.readlines()

guangantai_lines = extract_guangantai(lines)

# ===== å¹¶å‘æµ‹é€Ÿ =====
results = []
with concurrent.futures.ThreadPoolExecutor(max_workers=CONCURRENT_WORKERS) as executor:
    for res in executor.map(test_source, guangantai_lines):
        if res:
            results.append(res)

# ===== å†™å…¥ whitelist.txt =====
with open(WHITELIST_FILE, "w", encoding="utf-8") as f:
    for r in results:
        if r["http_status"] == 200 and r["playable"]:
            f.write(f"{r['name']},{r['url']}\n")

# ===== å†™å…¥ test_results.csv =====
with open(RESULTS_FILE, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["name","url","http_status","latency","playable"])
    writer.writeheader()
    writer.writerows(results)

print(f"âœ… æ¸¯æ¾³å°æµ‹é€Ÿå®Œæˆï¼Œå¯ç”¨æºå†™å…¥ {WHITELIST_FILE}ï¼Œè¯¦ç»†ç»“æœå†™å…¥ {RESULTS_FILE}")
