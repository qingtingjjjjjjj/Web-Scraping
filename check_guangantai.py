#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¹ live.txt ä¸­â€œæ¸¯æ¾³å°,#genre#â€åˆ†ç»„çš„ç›´æ’­æºæµ‹é€Ÿï¼ˆå“åº”æ—¶é—´ï¼‰ã€‚
è¾“å‡ºï¼š
  - æµ‹é€Ÿç»“æœ/æ¸¯æ¾³å°_test_results.csv
  - æµ‹é€Ÿç»“æœ/æ¸¯æ¾³å°_whitelist.txt
"""

import os
import re
import csv
import time
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

LIVE_FILE = "live.txt"
OUTPUT_DIR = "æµ‹é€Ÿç»“æœ"
WHITELIST_FILE = os.path.join(OUTPUT_DIR, "æ¸¯æ¾³å°_whitelist.txt")
RESULT_FILE = os.path.join(OUTPUT_DIR, "æ¸¯æ¾³å°_test_results.csv")

TARGET_GROUP = "æ¸¯æ¾³å°,#genre#"
TIMEOUT = 8
MAX_WORKERS = 10

os.makedirs(OUTPUT_DIR, exist_ok=True)


def parse_live_file(filepath):
    """æå– æ¸¯æ¾³å°,#genre# åˆ†ç»„ä¸‹çš„é¢‘é“ä¸URL"""
    entries = []
    current_group = None
    with open(filepath, encoding="utf-8", errors="ignore") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            # æ£€æµ‹åˆ†ç»„
            if line.endswith("#genre#"):
                current_group = line
                continue
            # æ¸¯æ¾³å°åˆ†ç»„ä¸‹çš„å†…å®¹
            if current_group == TARGET_GROUP:
                if "," in line:
                    name, url = line.split(",", 1)
                    if url.startswith("http"):
                        entries.append((name.strip(), url.strip()))
    return entries


def test_url(name, url):
    """æµ‹é€Ÿå‡½æ•°ï¼šè¿”å›å“åº”æ—¶é—´ï¼ˆç§’ï¼‰"""
    start = time.time()
    try:
        resp = requests.get(url, stream=True, timeout=TIMEOUT)
        elapsed = round(time.time() - start, 3)
        if resp.status_code == 200:
            return {"name": name, "url": url, "status": "OK", "time": elapsed}
        else:
            return {"name": name, "url": url, "status": f"HTTP {resp.status_code}", "time": elapsed}
    except Exception as e:
        return {"name": name, "url": url, "status": f"Fail: {e.__class__.__name__}", "time": None}


def main():
    if not os.path.exists(LIVE_FILE):
        print(f"âŒ æœªæ‰¾åˆ° {LIVE_FILE}")
        return

    entries = parse_live_file(LIVE_FILE)
    if not entries:
        print("âš ï¸ æœªæ‰¾åˆ° 'æ¸¯æ¾³å°,#genre#' åˆ†ç»„å†…å®¹ã€‚")
        return

    print(f"å‘ç° {len(entries)} æ¡ç›´æ’­æºï¼Œå¼€å§‹æµ‹é€Ÿ...")

    results = []
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = [executor.submit(test_url, name, url) for name, url in entries]
        for fut in as_completed(futures):
            res = fut.result()
            results.append(res)
            status = "âœ…" if res["status"] == "OK" else "âŒ"
            print(f"{status} {res['name']} - {res['url']}  [{res['status']}]  {res['time']}s")

    # å†™å…¥ CSV
    with open(RESULT_FILE, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "url", "status", "time"])
        writer.writeheader()
        writer.writerows(results)

    # å†™å…¥ç™½åå•
    ok_list = [r for r in results if r["status"] == "OK"]
    with open(WHITELIST_FILE, "w", encoding="utf-8") as f:
        for r in ok_list:
            f.write(f"{r['name']},{r['url']}\n")

    print(f"\nâœ… æµ‹é€Ÿå®Œæˆï¼Œå…± {len(ok_list)} æ¡å¯ç”¨æºã€‚")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨ï¼š{OUTPUT_DIR}/")


if __name__ == "__main__":
    main()
