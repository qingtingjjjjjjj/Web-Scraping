import requests
import os

# é…ç½®
SOURCE_URL = "https://raw.githubusercontent.com/wangchongzhq/wangchongzhq/2dbe3356a5a073fa4981f54c6b6e53e9117ca10e/109.txt"
OUTPUT_DIR = "ä¸“åŒº"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "å¤®è§†é¢‘é“.txt")
GROUP_KEYWORD = "ğŸ‡¨ğŸ‡³ 4K"

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)

# è·å–æºæ–‡ä»¶
def fetch_source(url):
    try:
        resp = requests.get(url, timeout=15)
        resp.encoding = 'utf-8'
        return resp.text
    except Exception as e:
        print(f"âŒ è·å–æºå¤±è´¥: {e}")
        return ""

# æå– ğŸ‡¨ğŸ‡³ 4K åˆ†ç»„
def extract_4k_group(content):
    lines = content.splitlines()
    result = []
    include_line = False

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # æ‰¾åˆ° 4K åˆ†ç»„
        if line == f"{GROUP_KEYWORD},#genre#":
            include_line = True
            result.append(line)
            continue

        # åˆ†ç»„å†…æŠ“å–ç›´æ’­æº
        if include_line:
            # é‡åˆ°ä¸‹ä¸€ä¸ªåˆ†ç»„åœæ­¢
            if ",#genre#" in line and GROUP_KEYWORD not in line:
                include_line = False
                continue
            # æå–é¢‘é“åç§°å’Œ URL
            parts = line.split(",", 1)
            if len(parts) == 2:
                result.append(f"{parts[0]}: {parts[1]}")

    return result

# ä¿å­˜åˆ°æ–‡ä»¶
def save_file(path, lines):
    with open(path, "w", encoding="utf-8-sig") as f:
        for line in lines:
            f.write(line + "\n")
    print(f"âœ… æ–‡ä»¶å·²ç”Ÿæˆ: {path}")

# ä¸»å‡½æ•°
def main():
    content = fetch_source(SOURCE_URL)
    if not content:
        return

    group_lines = extract_4k_group(content)

    if not group_lines:
        print("âš ï¸ æ²¡æœ‰æŠ“å–åˆ° ğŸ‡¨ğŸ‡³ 4K åˆ†ç»„å†…å®¹")
        return

    print(f"æ€»è®¡ {len([l for l in group_lines if l.startswith('http') or 'http' in l])} ä¸ª 4K ç›´æ’­æºæŠ“å–æˆåŠŸã€‚")
    save_file(OUTPUT_FILE, group_lines)

if __name__ == "__main__":
    main()
