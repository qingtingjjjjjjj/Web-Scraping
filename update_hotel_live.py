import requests
import os

# æ­£ç¡®çš„ç›´æ’­æº URL
SOURCE_URL = "https://raw.githubusercontent.com/wangchongzhq/wangchongzhq/2dbe3356a5a073fa4981f54c6b6e53e9117ca10e/109.txt"
OUTPUT_DIR = "ä¸“åŒº"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "4K.txt")  # ä¿®æ”¹è¾“å‡ºæ–‡ä»¶
GROUP_4K = "ğŸ‡¨ğŸ‡³ 4K"

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)

# è·å–æºæ–‡ä»¶
def fetch_source():
    resp = requests.get(SOURCE_URL, timeout=10)
    resp.encoding = 'utf-8'
    return resp.text

# æå– 4K åˆ†ç»„åŠå…¶ç›´æ’­æº
def extract_4k_group(content):
    lines = content.splitlines()
    result = []
    include_line = False
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if GROUP_4K in line:
            include_line = True
            result.append(line)
            continue
        if include_line:
            if ",#genre#" in line and GROUP_4K not in line:
                break
            parts = line.split(",", 1)
            if len(parts) == 2:
                result.append(f"{parts[0]}: {parts[1]}")
    return result

# ä¿å­˜åˆ°æ–‡ä»¶
def save_file(path, lines):
    with open(path, "w", encoding="utf-8-sig") as f:
        for line in lines:
            f.write(line + "\n")
    print(f"âœ… æ–‡ä»¶å·²ç”Ÿæˆ: {os.path.abspath(path)}")

# ä¸»å‡½æ•°
def main():
    content = fetch_source()
    if not content:
        print("âŒ æºæ–‡ä»¶ä¸ºç©º")
        return

    group_4k_lines = extract_4k_group(content)
    if not group_4k_lines:
        print("âš ï¸ æ²¡æœ‰æŠ“å–åˆ° ğŸ‡¨ğŸ‡³ 4K åˆ†ç»„å†…å®¹")
        return

    print(f"æ€»è®¡ {len([l for l in group_4k_lines if 'http' in l])} ä¸ª 4K ç›´æ’­æºæŠ“å–æˆåŠŸã€‚")
    save_file(OUTPUT_FILE, group_4k_lines)

if __name__ == "__main__":
    main()
