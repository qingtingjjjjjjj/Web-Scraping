import requests
import os

# ===== é…ç½® =====
SOURCE_URL = "https://raw.githubusercontent.com/wangchongzhq/wangchongzhq/2dbe3356a5a073fa4981f54c6b6e53e9117ca10e/109.txt"
OUTPUT_DIR = "ä¸“åŒº"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "å¤®è§†é¢‘é“.txt")
GROUP_KEYWORD = "ğŸ‡¨ğŸ‡³ 4K"

# ===== åˆ›å»ºè¾“å‡ºç›®å½• =====
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ===== è·å–æºæ–‡ä»¶ =====
def fetch_source(url):
    try:
        resp = requests.get(url, timeout=15)
        resp.encoding = 'utf-8'
        return resp.text
    except Exception as e:
        print(f"âŒ è·å–æºå¤±è´¥: {e}")
        return ""

# ===== æå– 4K åˆ†ç»„ =====
def extract_4k_group(content):
    lines = content.splitlines()
    result = []
    include_line = False

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # æ‰¾åˆ° 4K åˆ†ç»„
        if GROUP_KEYWORD in line:
            include_line = True
            result.append(line)
            continue

        # åˆ†ç»„å†…æŠ“å–ç›´æ’­æº
        if include_line:
            # é‡åˆ°ä¸‹ä¸€ä¸ªåˆ†ç»„åœæ­¢
            if ",#genre#" in line and GROUP_KEYWORD not in line:
                include_line = False
                continue
            result.append(line)

    return result

# ===== ä¿å­˜åˆ°æ–‡ä»¶ =====
def save_file(path, lines):
    with open(path, "w", encoding="utf-8-sig") as f:
        for line in lines:
            f.write(line + "\n")
    print(f"âœ… æ–‡ä»¶å·²ç”Ÿæˆ: {path}")

# ===== ä¸»å‡½æ•° =====
def main():
    content = fetch_source(SOURCE_URL)
    if not content:
        return

    group_lines = extract_4k_group(content)

    if not group_lines:
        print("âš ï¸ æ²¡æœ‰æŠ“å–åˆ° ğŸ‡¨ğŸ‡³ 4K åˆ†ç»„å†…å®¹")
        return

    # ç»Ÿè®¡æŠ“å–åˆ°çš„ç›´æ’­æºæ•°é‡
    live_count = sum(1 for l in group_lines if l.startswith("http"))
    print(f"æ€»è®¡ {live_count} ä¸ª 4K ç›´æ’­æºæŠ“å–æˆåŠŸã€‚")

    save_file(OUTPUT_FILE, group_lines)

if __name__ == "__main__":
    main()
